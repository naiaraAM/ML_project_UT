{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/naiaraAM/ML_project_UT/blob/main/Project_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzV8D8bXC4lw"
   },
   "source": [
    "# Set up enviroment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrh42OERGJnQ"
   },
   "source": [
    "# Download data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "MobMyN7kGOZS",
    "outputId": "e36928ec-8f8b-4f07-c8a1-6795bd4b8c92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open playground-series-s4e6.zip, playground-series-s4e6.zip.zip or playground-series-s4e6.zip.ZIP.\n",
      "rm: cannot remove 'playground-series-s4e6.zip': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!unzip -q playground-series-s4e6.zip -d data\n",
    "!rm playground-series-s4e6.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAKgcDH_F13K",
    "outputId": "ef4a9512-2644-4c37-85b7-5aadaf4304e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data has 76518 rows and 38 columns\n",
      "The test data has 51012 rows and 37 columns\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(f\"The train data has {train_data.shape[0]} rows and {train_data.shape[1]} columns\")\n",
    "print(f\"The test data has {test_data.shape[0]} rows and {test_data.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Do your code in the cell bellow your name, so we don't have merge issues. We can merge on friday's meeting</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naiara\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: Marital status\n",
      "Processing feature: Application mode\n",
      "Processing feature: Application order\n",
      "Processing feature: Course\n",
      "Processing feature: Daytime/evening attendance\n",
      "Error processing feature Daytime/evening attendance: [Errno 2] No such file or directory: '/gpfs/helios/home/naiara/machine_learning/ML_project_UT/plots/Daytime/evening attendance_percentage_plot.png'\n",
      "Processing feature: Previous qualification\n",
      "Processing feature: Nacionality\n",
      "Processing feature: Mother's qualification\n",
      "Processing feature: Father's qualification\n",
      "Processing feature: Mother's occupation\n",
      "Processing feature: Father's occupation\n",
      "Processing feature: Displaced\n",
      "Processing feature: Educational special needs\n",
      "Processing feature: Debtor\n",
      "Processing feature: Tuition fees up to date\n",
      "Processing feature: Gender\n",
      "Processing feature: Scholarship holder\n",
      "Processing feature: Age at enrollment\n",
      "Processing feature: International\n",
      "Processing feature: Curricular units 1st sem (credited)\n",
      "Processing feature: Curricular units 1st sem (enrolled)\n",
      "Processing feature: Curricular units 1st sem (evaluations)\n",
      "Processing feature: Curricular units 1st sem (approved)\n",
      "Processing feature: Curricular units 1st sem (without evaluations)\n",
      "Processing feature: Curricular units 2nd sem (credited)\n",
      "Processing feature: Curricular units 2nd sem (enrolled)\n",
      "Processing feature: Curricular units 2nd sem (evaluations)\n",
      "Processing feature: Curricular units 2nd sem (approved)\n",
      "Processing feature: Curricular units 2nd sem (without evaluations)\n",
      "Processing feature: Unemployment rate\n",
      "Processing feature: Inflation rate\n",
      "Processing feature: GDP\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import matplotlib\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "\n",
    "features = train_data.columns[:-1]\n",
    "\n",
    "max_unique_values = 100  # Different possible values for feature\n",
    "features = [f for f in features if train_data[f].nunique() <= max_unique_values]\n",
    "\n",
    "output_dir = 'plots'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "batch_size = 5\n",
    "for i in range(0, len(features), batch_size):\n",
    "    batch_features = features[i:i + batch_size]\n",
    "    \n",
    "    for feature in batch_features:\n",
    "        try:\n",
    "            print(f\"Processing feature: {feature}\")\n",
    "            percentage = train_data.groupby(feature)['Target'].value_counts(normalize=True).unstack() * 100\n",
    "            \n",
    "            # Plot and save\n",
    "            ax = percentage.plot(kind='bar', stacked=True, colormap='viridis', legend=False)\n",
    "            plt.xlabel(feature)\n",
    "            plt.ylabel('Percentage')\n",
    "            plt.title(f'Percentage of Each Target Value per {feature} Value')\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            plt.legend(handles, labels, title='Target')\n",
    "\n",
    "            # Save plot\n",
    "            plot_filename = os.path.join(output_dir, f'{feature}_percentage_plot.png')\n",
    "            plt.savefig(plot_filename)\n",
    "            plt.close()\n",
    "            #print(f\"Saved plot for feature: {feature}\")\n",
    "            \n",
    "            time.sleep(0.5)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing feature {feature}: {e}\")\n",
    "\n",
    "        gc.collect()  # Clear memory\n",
    "    \n",
    "    #print(f\"Batch {i // batch_size + 1} completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submitModel(model, X_test):\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    Y_tilda = model.predict(X_test_scaled)\n",
    "    submission = pd.DataFrame(\n",
    "        {'id': X_test[\"id\"], 'Target': Y_tilda},\n",
    "        columns = ['id', 'Target'])\n",
    "    submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitModel(best_model, test_data) # 0.82420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(models, filename: str):\n",
    "    for index, model in enumerate(models):\n",
    "        filename_aux = filename + f'_{index}.pkl'\n",
    "        with open(filename_aux, 'wb') as file:  \n",
    "            pickle.dump(model, file)\n",
    "            print(f\"Saved with the name {filename_aux}\")\n",
    "\n",
    "# TODO: I need to fix this\n",
    "def load_model(filename: str):\n",
    "    with open(filename, 'rb') as file:  \n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-equal performance on public-private score, public is always better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target\n",
      "Graduate    36282\n",
      "Dropout     25296\n",
      "Enrolled    14940\n",
      "Name: count, dtype: int64\n",
      "Validation Accuracy: 0.8287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86      5059\n",
      "           1       0.65      0.60      0.62      2988\n",
      "           2       0.85      0.92      0.89      7257\n",
      "\n",
      "    accuracy                           0.83     15304\n",
      "   macro avg       0.80      0.78      0.79     15304\n",
      "weighted avg       0.83      0.83      0.83     15304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "X = train_data.iloc[:, :-1]\n",
    "y = train_data.iloc[:, -1]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(y.value_counts())\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "gbt_model = GradientBoostingClassifier(n_estimators=350, learning_rate=0.03, max_depth=5)\n",
    "\n",
    "gbt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val = gbt_model.predict(X_val)\n",
    "\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "print(f\"Validation Accuracy: {accuracy_val:.4f}\")\n",
    "\n",
    "print(classification_report(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved with the name XXXXX_gbt_model.pkl\n",
      "Submission file saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "filename = \"XXXXX_gbt_model.pkl\"\n",
    "save_model(filename)\n",
    "#model = load_model(filename)\n",
    "\n",
    "y_test = model.predict(X_test_pca)\n",
    "y_test = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'id': test_data[\"id\"], 'Target': y_test},\n",
    "    columns=['id', 'Target']\n",
    ")\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved as 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9f600_row0_col3 {\n",
       "  background-color: #a70226;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f600_row0_col4 {\n",
       "  background-color: #fcaa5f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row0_col5 {\n",
       "  background-color: #ec5c3b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f600_row1_col3 {\n",
       "  background-color: #fdb163;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row1_col4 {\n",
       "  background-color: #fffebe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row1_col5 {\n",
       "  background-color: #fee28f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row2_col3 {\n",
       "  background-color: #fff7b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row2_col4 {\n",
       "  background-color: #cbe982;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row2_col5 {\n",
       "  background-color: #e5f49b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row3_col3 {\n",
       "  background-color: #fff3ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row3_col4 {\n",
       "  background-color: #bde379;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row3_col5 {\n",
       "  background-color: #d3ec87;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row4_col3 {\n",
       "  background-color: #fba05b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row4_col4 {\n",
       "  background-color: #c5e67e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row4_col5 {\n",
       "  background-color: #afdd70;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row5_col3 {\n",
       "  background-color: #b5df74;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row5_col4, #T_9f600_row5_col5 {\n",
       "  background-color: #bfe47a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row6_col3 {\n",
       "  background-color: #dff293;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row6_col4 {\n",
       "  background-color: #feca79;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row6_col5 {\n",
       "  background-color: #b9e176;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row7_col3 {\n",
       "  background-color: #c7e77f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row7_col4 {\n",
       "  background-color: #fdc372;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row7_col5 {\n",
       "  background-color: #f98e52;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9f600_row8_col3 {\n",
       "  background-color: #d7ee8a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row8_col4 {\n",
       "  background-color: #fdb567;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9f600_row8_col5 {\n",
       "  background-color: #e65036;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9f600\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9f600_level0_col0\" class=\"col_heading level0 col0\" >n_estimators</th>\n",
       "      <th id=\"T_9f600_level0_col1\" class=\"col_heading level0 col1\" >learning_rate</th>\n",
       "      <th id=\"T_9f600_level0_col2\" class=\"col_heading level0 col2\" >max_depth</th>\n",
       "      <th id=\"T_9f600_level0_col3\" class=\"col_heading level0 col3\" >accuracy</th>\n",
       "      <th id=\"T_9f600_level0_col4\" class=\"col_heading level0 col4\" >private score</th>\n",
       "      <th id=\"T_9f600_level0_col5\" class=\"col_heading level0 col5\" >public score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9f600_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9f600_row0_col0\" class=\"data row0 col0\" >200</td>\n",
       "      <td id=\"T_9f600_row0_col1\" class=\"data row0 col1\" >0.050000</td>\n",
       "      <td id=\"T_9f600_row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "      <td id=\"T_9f600_row0_col3\" class=\"data row0 col3\" >0.814900</td>\n",
       "      <td id=\"T_9f600_row0_col4\" class=\"data row0 col4\" >0.822270</td>\n",
       "      <td id=\"T_9f600_row0_col5\" class=\"data row0 col5\" >0.819150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f600_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9f600_row1_col0\" class=\"data row1 col0\" >200</td>\n",
       "      <td id=\"T_9f600_row1_col1\" class=\"data row1 col1\" >0.050000</td>\n",
       "      <td id=\"T_9f600_row1_col2\" class=\"data row1 col2\" >2</td>\n",
       "      <td id=\"T_9f600_row1_col3\" class=\"data row1 col3\" >0.822500</td>\n",
       "      <td id=\"T_9f600_row1_col4\" class=\"data row1 col4\" >0.827370</td>\n",
       "      <td id=\"T_9f600_row1_col5\" class=\"data row1 col5\" >0.825130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f600_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9f600_row2_col0\" class=\"data row2 col0\" >200</td>\n",
       "      <td id=\"T_9f600_row2_col1\" class=\"data row2 col1\" >0.050000</td>\n",
       "      <td id=\"T_9f600_row2_col2\" class=\"data row2 col2\" >3</td>\n",
       "      <td id=\"T_9f600_row2_col3\" class=\"data row2 col3\" >0.826800</td>\n",
       "      <td id=\"T_9f600_row2_col4\" class=\"data row2 col4\" >0.830550</td>\n",
       "      <td id=\"T_9f600_row2_col5\" class=\"data row2 col5\" >0.829150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f600_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9f600_row3_col0\" class=\"data row3 col0\" >200</td>\n",
       "      <td id=\"T_9f600_row3_col1\" class=\"data row3 col1\" >0.050000</td>\n",
       "      <td id=\"T_9f600_row3_col2\" class=\"data row3 col2\" >4</td>\n",
       "      <td id=\"T_9f600_row3_col3\" class=\"data row3 col3\" >0.826500</td>\n",
       "      <td id=\"T_9f600_row3_col4\" class=\"data row3 col4\" >0.831240</td>\n",
       "      <td id=\"T_9f600_row3_col5\" class=\"data row3 col5\" >0.830220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f600_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_9f600_row4_col0\" class=\"data row4 col0\" >200</td>\n",
       "      <td id=\"T_9f600_row4_col1\" class=\"data row4 col1\" >0.050000</td>\n",
       "      <td id=\"T_9f600_row4_col2\" class=\"data row4 col2\" >5</td>\n",
       "      <td id=\"T_9f600_row4_col3\" class=\"data row4 col3\" >0.821800</td>\n",
       "      <td id=\"T_9f600_row4_col4\" class=\"data row4 col4\" >0.830940</td>\n",
       "      <td id=\"T_9f600_row4_col5\" class=\"data row4 col5\" >0.831990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f600_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_9f600_row5_col0\" class=\"data row5 col0\" >200</td>\n",
       "      <td id=\"T_9f600_row5_col1\" class=\"data row5 col1\" >0.050000</td>\n",
       "      <td id=\"T_9f600_row5_col2\" class=\"data row5 col2\" >6</td>\n",
       "      <td id=\"T_9f600_row5_col3\" class=\"data row5 col3\" >0.831700</td>\n",
       "      <td id=\"T_9f600_row5_col4\" class=\"data row5 col4\" >0.831190</td>\n",
       "      <td id=\"T_9f600_row5_col5\" class=\"data row5 col5\" >0.831200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f600_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_9f600_row6_col0\" class=\"data row6 col0\" >200</td>\n",
       "      <td id=\"T_9f600_row6_col1\" class=\"data row6 col1\" >0.050000</td>\n",
       "      <td id=\"T_9f600_row6_col2\" class=\"data row6 col2\" >7</td>\n",
       "      <td id=\"T_9f600_row6_col3\" class=\"data row6 col3\" >0.829500</td>\n",
       "      <td id=\"T_9f600_row6_col4\" class=\"data row6 col4\" >0.823780</td>\n",
       "      <td id=\"T_9f600_row6_col5\" class=\"data row6 col5\" >0.831500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f600_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_9f600_row7_col0\" class=\"data row7 col0\" >200</td>\n",
       "      <td id=\"T_9f600_row7_col1\" class=\"data row7 col1\" >0.050000</td>\n",
       "      <td id=\"T_9f600_row7_col2\" class=\"data row7 col2\" >8</td>\n",
       "      <td id=\"T_9f600_row7_col3\" class=\"data row7 col3\" >0.830800</td>\n",
       "      <td id=\"T_9f600_row7_col4\" class=\"data row7 col4\" >0.823370</td>\n",
       "      <td id=\"T_9f600_row7_col5\" class=\"data row7 col5\" >0.821110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f600_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_9f600_row8_col0\" class=\"data row8 col0\" >200</td>\n",
       "      <td id=\"T_9f600_row8_col1\" class=\"data row8 col1\" >0.050000</td>\n",
       "      <td id=\"T_9f600_row8_col2\" class=\"data row8 col2\" >9</td>\n",
       "      <td id=\"T_9f600_row8_col3\" class=\"data row8 col3\" >0.830000</td>\n",
       "      <td id=\"T_9f600_row8_col4\" class=\"data row8 col4\" >0.822760</td>\n",
       "      <td id=\"T_9f600_row8_col5\" class=\"data row8 col5\" >0.818660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1488565d8ca0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_depth = {\n",
    "    'n_estimators': [200, 200, 200, 200, 200, 200, 200, 200, 200],\n",
    "    'learning_rate': [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05],\n",
    "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'accuracy': [0.8149, 0.8225, 0.8268, 0.8265, 0.8218, 0.8317, 0.8295, 0.8308, 0.8300],\n",
    "    'private score': [0.82227, 0.82737, 0.83055, 0.83124, 0.83094, 0.83119, 0.82378, 0.82337, 0.82276],\n",
    "    'public score': [0.81915, 0.82513, 0.82915, 0.83022, 0.83199, 0.83120, 0.83150, 0.82111, 0.81866]\n",
    "}\n",
    "\n",
    "df_depth = pd.DataFrame(data_depth)\n",
    "\n",
    "df_styled = df_depth.style.background_gradient(subset=[\"accuracy\", \"public score\", \"private score\"], cmap=\"RdYlGn\", vmin=0.8148, vmax=0.84)\n",
    "\n",
    "df_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d0b15_row0_col3 {\n",
       "  background-color: #d42d27;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d0b15_row0_col4 {\n",
       "  background-color: #fa9656;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d0b15_row0_col5 {\n",
       "  background-color: #f26841;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d0b15_row1_col3 {\n",
       "  background-color: #fee999;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d0b15_row1_col4 {\n",
       "  background-color: #fff2aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d0b15_row1_col5 {\n",
       "  background-color: #fed683;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d0b15_row2_col3, #T_d0b15_row3_col3 {\n",
       "  background-color: #fffdbc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d0b15_row2_col4 {\n",
       "  background-color: #eff8aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d0b15_row2_col5 {\n",
       "  background-color: #fede89;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d0b15_row3_col4 {\n",
       "  background-color: #f7fcb4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d0b15_row3_col5 {\n",
       "  background-color: #fbfdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d0b15_row4_col3 {\n",
       "  background-color: #fdfebc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d0b15_row4_col4 {\n",
       "  background-color: #fff1a8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d0b15_row4_col5 {\n",
       "  background-color: #e5f49b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d0b15_row5_col3 {\n",
       "  background-color: #fff3ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d0b15_row5_col4 {\n",
       "  background-color: #ed5f3c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d0b15_row5_col5 {\n",
       "  background-color: #ea5739;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d0b15\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d0b15_level0_col0\" class=\"col_heading level0 col0\" >n_estimators</th>\n",
       "      <th id=\"T_d0b15_level0_col1\" class=\"col_heading level0 col1\" >learning_rate</th>\n",
       "      <th id=\"T_d0b15_level0_col2\" class=\"col_heading level0 col2\" >max_depth</th>\n",
       "      <th id=\"T_d0b15_level0_col3\" class=\"col_heading level0 col3\" >accuracy</th>\n",
       "      <th id=\"T_d0b15_level0_col4\" class=\"col_heading level0 col4\" >private score</th>\n",
       "      <th id=\"T_d0b15_level0_col5\" class=\"col_heading level0 col5\" >public score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d0b15_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d0b15_row0_col0\" class=\"data row0 col0\" >200</td>\n",
       "      <td id=\"T_d0b15_row0_col1\" class=\"data row0 col1\" >0.010000</td>\n",
       "      <td id=\"T_d0b15_row0_col2\" class=\"data row0 col2\" >6</td>\n",
       "      <td id=\"T_d0b15_row0_col3\" class=\"data row0 col3\" >0.822800</td>\n",
       "      <td id=\"T_d0b15_row0_col4\" class=\"data row0 col4\" >0.825990</td>\n",
       "      <td id=\"T_d0b15_row0_col5\" class=\"data row0 col5\" >0.824640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d0b15_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d0b15_row1_col0\" class=\"data row1 col0\" >200</td>\n",
       "      <td id=\"T_d0b15_row1_col1\" class=\"data row1 col1\" >0.020000</td>\n",
       "      <td id=\"T_d0b15_row1_col2\" class=\"data row1 col2\" >6</td>\n",
       "      <td id=\"T_d0b15_row1_col3\" class=\"data row1 col3\" >0.829100</td>\n",
       "      <td id=\"T_d0b15_row1_col4\" class=\"data row1 col4\" >0.829690</td>\n",
       "      <td id=\"T_d0b15_row1_col5\" class=\"data row1 col5\" >0.828260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d0b15_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d0b15_row2_col0\" class=\"data row2 col0\" >200</td>\n",
       "      <td id=\"T_d0b15_row2_col1\" class=\"data row2 col1\" >0.030000</td>\n",
       "      <td id=\"T_d0b15_row2_col2\" class=\"data row2 col2\" >6</td>\n",
       "      <td id=\"T_d0b15_row2_col3\" class=\"data row2 col3\" >0.830400</td>\n",
       "      <td id=\"T_d0b15_row2_col4\" class=\"data row2 col4\" >0.831260</td>\n",
       "      <td id=\"T_d0b15_row2_col5\" class=\"data row2 col5\" >0.828560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d0b15_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d0b15_row3_col0\" class=\"data row3 col0\" >200</td>\n",
       "      <td id=\"T_d0b15_row3_col1\" class=\"data row3 col1\" >0.040000</td>\n",
       "      <td id=\"T_d0b15_row3_col2\" class=\"data row3 col2\" >6</td>\n",
       "      <td id=\"T_d0b15_row3_col3\" class=\"data row3 col3\" >0.830400</td>\n",
       "      <td id=\"T_d0b15_row3_col4\" class=\"data row3 col4\" >0.830940</td>\n",
       "      <td id=\"T_d0b15_row3_col5\" class=\"data row3 col5\" >0.830710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d0b15_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d0b15_row4_col0\" class=\"data row4 col0\" >200</td>\n",
       "      <td id=\"T_d0b15_row4_col1\" class=\"data row4 col1\" >0.050000</td>\n",
       "      <td id=\"T_d0b15_row4_col2\" class=\"data row4 col2\" >6</td>\n",
       "      <td id=\"T_d0b15_row4_col3\" class=\"data row4 col3\" >0.830600</td>\n",
       "      <td id=\"T_d0b15_row4_col4\" class=\"data row4 col4\" >0.829670</td>\n",
       "      <td id=\"T_d0b15_row4_col5\" class=\"data row4 col5\" >0.831790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d0b15_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d0b15_row5_col0\" class=\"data row5 col0\" >200</td>\n",
       "      <td id=\"T_d0b15_row5_col1\" class=\"data row5 col1\" >0.060000</td>\n",
       "      <td id=\"T_d0b15_row5_col2\" class=\"data row5 col2\" >6</td>\n",
       "      <td id=\"T_d0b15_row5_col3\" class=\"data row5 col3\" >0.829800</td>\n",
       "      <td id=\"T_d0b15_row5_col4\" class=\"data row5 col4\" >0.824350</td>\n",
       "      <td id=\"T_d0b15_row5_col5\" class=\"data row5 col5\" >0.824150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1488ace15be0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_learning_rate = {\n",
    "    'n_estimators': [200, 200, 200, 200, 200, 200],\n",
    "    'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06],\n",
    "    'max_depth': [6, 6, 6, 6, 6, 6],\n",
    "    'accuracy': [0.8228, 0.8291, 0.8304, 0.8304, 0.8306, 0.8298],\n",
    "    'private score': [0.82599, 0.82969, 0.83126, 0.83094, 0.82967, 0.82435],\n",
    "    'public score': [0.82464, 0.82826, 0.82856, 0.83071, 0.83179, 0.82415]\n",
    "}\n",
    "\n",
    "df_learning_rate = pd.DataFrame(data_learning_rate)\n",
    "\n",
    "df_styled = df_learning_rate.style.background_gradient(subset=[\"accuracy\", \"public score\", \"private score\"], cmap=\"RdYlGn\", vmin=0.821, vmax=0.84)\n",
    "\n",
    "df_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9deb1_row0_col3 {\n",
       "  background-color: #f47044;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9deb1_row0_col4 {\n",
       "  background-color: #fdc574;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row0_col5 {\n",
       "  background-color: #fdb567;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row1_col3 {\n",
       "  background-color: #fede89;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row1_col4 {\n",
       "  background-color: #fff8b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row1_col5 {\n",
       "  background-color: #fee18d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row2_col3 {\n",
       "  background-color: #fbfdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row2_col4 {\n",
       "  background-color: #eef8a8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row2_col5 {\n",
       "  background-color: #fffebe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row3_col3 {\n",
       "  background-color: #eff8aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row3_col4 {\n",
       "  background-color: #dcf08f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row3_col5, #T_9deb1_row4_col5 {\n",
       "  background-color: #ecf7a6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row4_col3 {\n",
       "  background-color: #e3f399;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row4_col4, #T_9deb1_row8_col5 {\n",
       "  background-color: #c5e67e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row5_col3 {\n",
       "  background-color: #ddf191;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row5_col4, #T_9deb1_row9_col3 {\n",
       "  background-color: #c1e57b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row5_col5 {\n",
       "  background-color: #ebf7a3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row6_col3 {\n",
       "  background-color: #cfeb85;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row6_col4 {\n",
       "  background-color: #b9e176;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row6_col5 {\n",
       "  background-color: #f8fcb6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row7_col3 {\n",
       "  background-color: #cbe982;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row7_col4 {\n",
       "  background-color: #d7ee8a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row7_col5 {\n",
       "  background-color: #d3ec87;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row8_col3, #T_9deb1_row10_col3 {\n",
       "  background-color: #bbe278;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row8_col4 {\n",
       "  background-color: #d1ec86;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row9_col4 {\n",
       "  background-color: #c7e77f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row9_col5, #T_9deb1_row10_col4 {\n",
       "  background-color: #cdea83;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9deb1_row10_col5 {\n",
       "  background-color: #bfe47a;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9deb1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9deb1_level0_col0\" class=\"col_heading level0 col0\" >n_estimators</th>\n",
       "      <th id=\"T_9deb1_level0_col1\" class=\"col_heading level0 col1\" >learning_rate</th>\n",
       "      <th id=\"T_9deb1_level0_col2\" class=\"col_heading level0 col2\" >max_depth</th>\n",
       "      <th id=\"T_9deb1_level0_col3\" class=\"col_heading level0 col3\" >accuracy</th>\n",
       "      <th id=\"T_9deb1_level0_col4\" class=\"col_heading level0 col4\" >private score</th>\n",
       "      <th id=\"T_9deb1_level0_col5\" class=\"col_heading level0 col5\" >public score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9deb1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9deb1_row0_col0\" class=\"data row0 col0\" >50</td>\n",
       "      <td id=\"T_9deb1_row0_col1\" class=\"data row0 col1\" >0.030000</td>\n",
       "      <td id=\"T_9deb1_row0_col2\" class=\"data row0 col2\" >6</td>\n",
       "      <td id=\"T_9deb1_row0_col3\" class=\"data row0 col3\" >0.820000</td>\n",
       "      <td id=\"T_9deb1_row0_col4\" class=\"data row0 col4\" >0.823490</td>\n",
       "      <td id=\"T_9deb1_row0_col5\" class=\"data row0 col5\" >0.822680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9deb1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9deb1_row1_col0\" class=\"data row1 col0\" >75</td>\n",
       "      <td id=\"T_9deb1_row1_col1\" class=\"data row1 col1\" >0.030000</td>\n",
       "      <td id=\"T_9deb1_row1_col2\" class=\"data row1 col2\" >6</td>\n",
       "      <td id=\"T_9deb1_row1_col3\" class=\"data row1 col3\" >0.824800</td>\n",
       "      <td id=\"T_9deb1_row1_col4\" class=\"data row1 col4\" >0.826830</td>\n",
       "      <td id=\"T_9deb1_row1_col5\" class=\"data row1 col5\" >0.825030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9deb1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9deb1_row2_col0\" class=\"data row2 col0\" >100</td>\n",
       "      <td id=\"T_9deb1_row2_col1\" class=\"data row2 col1\" >0.030000</td>\n",
       "      <td id=\"T_9deb1_row2_col2\" class=\"data row2 col2\" >6</td>\n",
       "      <td id=\"T_9deb1_row2_col3\" class=\"data row2 col3\" >0.827600</td>\n",
       "      <td id=\"T_9deb1_row2_col4\" class=\"data row2 col4\" >0.828540</td>\n",
       "      <td id=\"T_9deb1_row2_col5\" class=\"data row2 col5\" >0.827380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9deb1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9deb1_row3_col0\" class=\"data row3 col0\" >125</td>\n",
       "      <td id=\"T_9deb1_row3_col1\" class=\"data row3 col1\" >0.030000</td>\n",
       "      <td id=\"T_9deb1_row3_col2\" class=\"data row3 col2\" >6</td>\n",
       "      <td id=\"T_9deb1_row3_col3\" class=\"data row3 col3\" >0.828400</td>\n",
       "      <td id=\"T_9deb1_row3_col4\" class=\"data row3 col4\" >0.829670</td>\n",
       "      <td id=\"T_9deb1_row3_col5\" class=\"data row3 col5\" >0.828660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9deb1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_9deb1_row4_col0\" class=\"data row4 col0\" >150</td>\n",
       "      <td id=\"T_9deb1_row4_col1\" class=\"data row4 col1\" >0.030000</td>\n",
       "      <td id=\"T_9deb1_row4_col2\" class=\"data row4 col2\" >6</td>\n",
       "      <td id=\"T_9deb1_row4_col3\" class=\"data row4 col3\" >0.829200</td>\n",
       "      <td id=\"T_9deb1_row4_col4\" class=\"data row4 col4\" >0.830920</td>\n",
       "      <td id=\"T_9deb1_row4_col5\" class=\"data row4 col5\" >0.828660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9deb1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_9deb1_row5_col0\" class=\"data row5 col0\" >175</td>\n",
       "      <td id=\"T_9deb1_row5_col1\" class=\"data row5 col1\" >0.030000</td>\n",
       "      <td id=\"T_9deb1_row5_col2\" class=\"data row5 col2\" >6</td>\n",
       "      <td id=\"T_9deb1_row5_col3\" class=\"data row5 col3\" >0.829600</td>\n",
       "      <td id=\"T_9deb1_row5_col4\" class=\"data row5 col4\" >0.831090</td>\n",
       "      <td id=\"T_9deb1_row5_col5\" class=\"data row5 col5\" >0.828750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9deb1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_9deb1_row6_col0\" class=\"data row6 col0\" >200</td>\n",
       "      <td id=\"T_9deb1_row6_col1\" class=\"data row6 col1\" >0.030000</td>\n",
       "      <td id=\"T_9deb1_row6_col2\" class=\"data row6 col2\" >6</td>\n",
       "      <td id=\"T_9deb1_row6_col3\" class=\"data row6 col3\" >0.830400</td>\n",
       "      <td id=\"T_9deb1_row6_col4\" class=\"data row6 col4\" >0.831460</td>\n",
       "      <td id=\"T_9deb1_row6_col5\" class=\"data row6 col5\" >0.827870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9deb1_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_9deb1_row7_col0\" class=\"data row7 col0\" >225</td>\n",
       "      <td id=\"T_9deb1_row7_col1\" class=\"data row7 col1\" >0.030000</td>\n",
       "      <td id=\"T_9deb1_row7_col2\" class=\"data row7 col2\" >6</td>\n",
       "      <td id=\"T_9deb1_row7_col3\" class=\"data row7 col3\" >0.830600</td>\n",
       "      <td id=\"T_9deb1_row7_col4\" class=\"data row7 col4\" >0.830020</td>\n",
       "      <td id=\"T_9deb1_row7_col5\" class=\"data row7 col5\" >0.830220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9deb1_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_9deb1_row8_col0\" class=\"data row8 col0\" >250</td>\n",
       "      <td id=\"T_9deb1_row8_col1\" class=\"data row8 col1\" >0.030000</td>\n",
       "      <td id=\"T_9deb1_row8_col2\" class=\"data row8 col2\" >6</td>\n",
       "      <td id=\"T_9deb1_row8_col3\" class=\"data row8 col3\" >0.831400</td>\n",
       "      <td id=\"T_9deb1_row8_col4\" class=\"data row8 col4\" >0.830330</td>\n",
       "      <td id=\"T_9deb1_row8_col5\" class=\"data row8 col5\" >0.830910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9deb1_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_9deb1_row9_col0\" class=\"data row9 col0\" >275</td>\n",
       "      <td id=\"T_9deb1_row9_col1\" class=\"data row9 col1\" >0.030000</td>\n",
       "      <td id=\"T_9deb1_row9_col2\" class=\"data row9 col2\" >6</td>\n",
       "      <td id=\"T_9deb1_row9_col3\" class=\"data row9 col3\" >0.831100</td>\n",
       "      <td id=\"T_9deb1_row9_col4\" class=\"data row9 col4\" >0.830750</td>\n",
       "      <td id=\"T_9deb1_row9_col5\" class=\"data row9 col5\" >0.830520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9deb1_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_9deb1_row10_col0\" class=\"data row10 col0\" >300</td>\n",
       "      <td id=\"T_9deb1_row10_col1\" class=\"data row10 col1\" >0.030000</td>\n",
       "      <td id=\"T_9deb1_row10_col2\" class=\"data row10 col2\" >6</td>\n",
       "      <td id=\"T_9deb1_row10_col3\" class=\"data row10 col3\" >0.831400</td>\n",
       "      <td id=\"T_9deb1_row10_col4\" class=\"data row10 col4\" >0.830530</td>\n",
       "      <td id=\"T_9deb1_row10_col5\" class=\"data row10 col5\" >0.831200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14885354e2b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_estimators = {\n",
    "    'n_estimators': [50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300],\n",
    "    'learning_rate': [0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03],\n",
    "    'max_depth': [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6],\n",
    "    'accuracy': [0.8200, 0.8248, 0.8276, 0.8284, 0.8292, 0.8296, 0.8304, 0.8306, 0.8314, 0.8311, 0.8314],\n",
    "    'private score': [0.82349, 0.82683, 0.82854, 0.82967, 0.83092, 0.83109, 0.83146, 0.83002, 0.83033, 0.83075, 0.83053],\n",
    "    'public score': [0.82268, 0.82503, 0.82738, 0.82866, 0.82866, 0.82875, 0.82787, 0.83022, 0.83091, 0.83052, 0.83120]\n",
    "}\n",
    "\n",
    "df_estimators = pd.DataFrame(data_estimators)\n",
    "\n",
    "df_styled = df_estimators.style.background_gradient(subset=[\"accuracy\", \"public score\", \"private score\"], cmap=\"RdYlGn\", vmin=0.8148, vmax=0.84)\n",
    "\n",
    "df_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_717b7_row0_col3, #T_717b7_row1_col3 {\n",
       "  background-color: #c7e77f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_717b7_row0_col4 {\n",
       "  background-color: #b1de71;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_717b7_row1_col4 {\n",
       "  background-color: #a7d96b;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_717b7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_717b7_level0_col0\" class=\"col_heading level0 col0\" >n_estimators</th>\n",
       "      <th id=\"T_717b7_level0_col1\" class=\"col_heading level0 col1\" >learning_rate</th>\n",
       "      <th id=\"T_717b7_level0_col2\" class=\"col_heading level0 col2\" >max_depth</th>\n",
       "      <th id=\"T_717b7_level0_col3\" class=\"col_heading level0 col3\" >private score</th>\n",
       "      <th id=\"T_717b7_level0_col4\" class=\"col_heading level0 col4\" >public score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_717b7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_717b7_row0_col0\" class=\"data row0 col0\" >300</td>\n",
       "      <td id=\"T_717b7_row0_col1\" class=\"data row0 col1\" >0.030000</td>\n",
       "      <td id=\"T_717b7_row0_col2\" class=\"data row0 col2\" >5</td>\n",
       "      <td id=\"T_717b7_row0_col3\" class=\"data row0 col3\" >0.830800</td>\n",
       "      <td id=\"T_717b7_row0_col4\" class=\"data row0 col4\" >0.831890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_717b7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_717b7_row1_col0\" class=\"data row1 col0\" >350</td>\n",
       "      <td id=\"T_717b7_row1_col1\" class=\"data row1 col1\" >0.030000</td>\n",
       "      <td id=\"T_717b7_row1_col2\" class=\"data row1 col2\" >5</td>\n",
       "      <td id=\"T_717b7_row1_col3\" class=\"data row1 col3\" >0.830820</td>\n",
       "      <td id=\"T_717b7_row1_col4\" class=\"data row1 col4\" >0.832380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14885354ebb0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_estimators = {\n",
    "    'n_estimators': [300, 350],\n",
    "    'learning_rate': [0.03, 0.03],\n",
    "    'max_depth': [5, 5],\n",
    "    'private score': [0.83080, 0.83082],\n",
    "    'public score': [0.83189, 0.83238]\n",
    "}\n",
    "\n",
    "df_estimators = pd.DataFrame(data_estimators)\n",
    "\n",
    "df_styled = df_estimators.style.background_gradient(subset=[\"public score\", \"private score\"], cmap=\"RdYlGn\", vmin=0.8148, vmax=0.84)\n",
    "\n",
    "df_styled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has similar performance on private-public, but the other approach is better.\n",
    "\n",
    "What this approach does. Separated the tags into three groups:\n",
    "* 0 and 1 (after label encoder)\n",
    "* 0 and 2 (after label encoder)\n",
    "* 1 and 2 (after label encoder)\n",
    "  \n",
    "Train the three models separately. Then combines\n",
    "* if prediction from `model_01` and `model_02`, then prediction is `0`\n",
    "* if prediction from `model_01` and `model_12`, then prediction is `1`\n",
    "* if prediction from `model_02` and `model_12`, then prediction is `2`\n",
    "* else majority voting\n",
    "\n",
    "I realised that the models struggle to predict for class `1`. If I change the `GradientBoostingClassifier` to `HistGradientBoostingClassifier` it performs a little b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for model 01: 0.8525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88      5059\n",
      "           1       0.76      0.87      0.81      2988\n",
      "\n",
      "    accuracy                           0.85      8047\n",
      "   macro avg       0.84      0.86      0.85      8047\n",
      "weighted avg       0.86      0.85      0.85      8047\n",
      "\n",
      "Validation Accuracy for model 02: 0.9445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      5059\n",
      "           2       0.94      0.97      0.95      7257\n",
      "\n",
      "    accuracy                           0.94     12316\n",
      "   macro avg       0.95      0.94      0.94     12316\n",
      "weighted avg       0.94      0.94      0.94     12316\n",
      "\n",
      "Validation Accuracy for model 12: 0.8682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.71      0.76      2988\n",
      "           2       0.89      0.93      0.91      7257\n",
      "\n",
      "    accuracy                           0.87     10245\n",
      "   macro avg       0.85      0.82      0.83     10245\n",
      "weighted avg       0.87      0.87      0.87     10245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "X = train_data.iloc[:, :-1]\n",
    "y = train_data.iloc[:, -1]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "X_train_01 = X_train[(y_train == 0) | (y_train == 1)]\n",
    "y_train_01 = y_train[(y_train == 0) | (y_train == 1)]\n",
    "X_val_01 = X_val[(y_val == 0) | (y_val == 1)]\n",
    "y_val_01 = y_val[(y_val == 0) | (y_val == 1)]\n",
    "\n",
    "X_train_02 = X_train[(y_train == 0) | (y_train == 2)]\n",
    "y_train_02 = y_train[(y_train == 0) | (y_train == 2)]\n",
    "X_val_02 = X_val[(y_val == 0) | (y_val == 2)]\n",
    "y_val_02 = y_val[(y_val == 0) | (y_val == 2)]\n",
    "\n",
    "X_train_12 = X_train[(y_train == 1) | (y_train == 2)]\n",
    "y_train_12 = y_train[(y_train == 1) | (y_train == 2)]\n",
    "X_val_12 = X_val[(y_val == 1) | (y_val == 2)]\n",
    "y_val_12 = y_val[(y_val == 1) | (y_val == 2)]\n",
    "\n",
    "model_01 = GradientBoostingClassifier(n_estimators=350, learning_rate=0.03, max_depth=5)\n",
    "model_01.fit(X_train_01, y_train_01)\n",
    "y_pred_val_01 = model_01.predict(X_val_01)\n",
    "accuracy_val = accuracy_score(y_val_01, y_pred_val_01)\n",
    "print(f\"Validation Accuracy for model 01: {accuracy_val:.4f}\")\n",
    "print(classification_report(y_val_01, y_pred_val_01))\n",
    "\n",
    "model_02 = GradientBoostingClassifier(n_estimators=350, learning_rate=0.03, max_depth=5)\n",
    "model_02.fit(X_train_02, y_train_02)\n",
    "y_pred_val_02 = model_02.predict(X_val_02)\n",
    "accuracy_val = accuracy_score(y_val_02, y_pred_val_02)\n",
    "print(f\"Validation Accuracy for model 02: {accuracy_val:.4f}\")\n",
    "print(classification_report(y_val_02, y_pred_val_02))\n",
    "\n",
    "model_12 = GradientBoostingClassifier(n_estimators=350, learning_rate=0.03, max_depth=5)\n",
    "model_12.fit(X_train_12, y_train_12)\n",
    "y_pred_val_12 = model_12.predict(X_val_12)\n",
    "accuracy_val = accuracy_score(y_val_12, y_pred_val_12)\n",
    "print(f\"Validation Accuracy for model 12: {accuracy_val:.4f}\")\n",
    "print(classification_report(y_val_12, y_pred_val_12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for Ensemble Model: 0.8280\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86      5059\n",
      "           1       0.64      0.60      0.62      2988\n",
      "           2       0.85      0.92      0.89      7257\n",
      "\n",
      "    accuracy                           0.83     15304\n",
      "   macro avg       0.80      0.78      0.79     15304\n",
      "weighted avg       0.83      0.83      0.83     15304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "def predict(X_data):\n",
    "    final_predictions = []\n",
    "    \n",
    "    for X_pred_data in X_data:\n",
    "        # Predictions for every model\n",
    "        predict_01 = model_01.predict([X_pred_data])[0]\n",
    "        predict_02 = model_02.predict([X_pred_data])[0]\n",
    "        predict_12 = model_12.predict([X_pred_data])[0]\n",
    "        \n",
    "        if predict_01 == predict_02:  # High chance of being class 0\n",
    "            prediction = 0\n",
    "        elif predict_01 == predict_12:  # High change of being class 1\n",
    "            prediction = 1\n",
    "        elif predict_02 == predict_12:  # High chance of being class 2\n",
    "            prediction = 2\n",
    "        else:  # mayority voto\n",
    "            votes = [predict_01, predict_02, predict_12]\n",
    "            prediction = max(set(votes), key=votes.count)\n",
    "        final_predictions.append(prediction)\n",
    "    return np.array(final_predictions)\n",
    "    \n",
    "final_predictions = predict(X_val)\n",
    "\n",
    "accuracy_val_ensemble = accuracy_score(y_val, final_predictions)\n",
    "print(f\"Validation Accuracy for Ensemble Model: {accuracy_val_ensemble:.4f}\")\n",
    "\n",
    "print(classification_report(y_val, final_predictions, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved with the name XXXXX_gbc_ensemble_model_0.pkl\n",
      "Saved with the name XXXXX_gbc_ensemble_model_1.pkl\n",
      "Saved with the name XXXXX_gbc_ensemble_model_2.pkl\n",
      "Submission file saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "models = [model_01, model_02, model_12]\n",
    "filename = \"XXXXX_gbc_ensemble_model\"\n",
    "save_model(models, filename)\n",
    "#model = load_model(filename)\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(test_data)\n",
    "final_predictions = predict(X_scaled)\n",
    "y_test = label_encoder.inverse_transform(final_predictions)\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'id': test_data[\"id\"], 'Target': y_test},\n",
    "    columns=['id', 'Target']\n",
    ")\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved as 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518.000000</td>\n",
       "      <td>76518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38258.500000</td>\n",
       "      <td>1.111934</td>\n",
       "      <td>16.054419</td>\n",
       "      <td>1.644410</td>\n",
       "      <td>9001.286377</td>\n",
       "      <td>0.915314</td>\n",
       "      <td>3.658760</td>\n",
       "      <td>132.378766</td>\n",
       "      <td>1.226600</td>\n",
       "      <td>19.837633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137053</td>\n",
       "      <td>5.933414</td>\n",
       "      <td>7.234468</td>\n",
       "      <td>4.007201</td>\n",
       "      <td>9.626085</td>\n",
       "      <td>0.062443</td>\n",
       "      <td>11.520340</td>\n",
       "      <td>1.228218</td>\n",
       "      <td>-0.080921</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22088.988286</td>\n",
       "      <td>0.441669</td>\n",
       "      <td>16.682337</td>\n",
       "      <td>1.229645</td>\n",
       "      <td>1803.438531</td>\n",
       "      <td>0.278416</td>\n",
       "      <td>8.623774</td>\n",
       "      <td>10.995328</td>\n",
       "      <td>3.392183</td>\n",
       "      <td>15.399456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933830</td>\n",
       "      <td>1.627182</td>\n",
       "      <td>3.503040</td>\n",
       "      <td>2.772956</td>\n",
       "      <td>5.546035</td>\n",
       "      <td>0.462107</td>\n",
       "      <td>2.653375</td>\n",
       "      <td>1.398816</td>\n",
       "      <td>2.251382</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-4.060000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19129.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9119.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>-1.700000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38258.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9254.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>133.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>57387.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9670.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.244048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>76517.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9991.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows  38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  Marital status  Application mode  Application order  \\\n",
       "count   76518.000000    76518.000000      76518.000000       76518.000000   \n",
       "unique           NaN             NaN               NaN                NaN   \n",
       "top              NaN             NaN               NaN                NaN   \n",
       "freq             NaN             NaN               NaN                NaN   \n",
       "mean    38258.500000        1.111934         16.054419           1.644410   \n",
       "std     22088.988286        0.441669         16.682337           1.229645   \n",
       "min         0.000000        1.000000          1.000000           0.000000   \n",
       "25%     19129.250000        1.000000          1.000000           1.000000   \n",
       "50%     38258.500000        1.000000         17.000000           1.000000   \n",
       "75%     57387.750000        1.000000         39.000000           2.000000   \n",
       "max     76517.000000        6.000000         53.000000           9.000000   \n",
       "\n",
       "              Course  Daytime/evening attendance  Previous qualification  \\\n",
       "count   76518.000000                76518.000000            76518.000000   \n",
       "unique           NaN                         NaN                     NaN   \n",
       "top              NaN                         NaN                     NaN   \n",
       "freq             NaN                         NaN                     NaN   \n",
       "mean     9001.286377                    0.915314                3.658760   \n",
       "std      1803.438531                    0.278416                8.623774   \n",
       "min        33.000000                    0.000000                1.000000   \n",
       "25%      9119.000000                    1.000000                1.000000   \n",
       "50%      9254.000000                    1.000000                1.000000   \n",
       "75%      9670.000000                    1.000000                1.000000   \n",
       "max      9991.000000                    1.000000               43.000000   \n",
       "\n",
       "        Previous qualification (grade)   Nacionality  Mother's qualification  \\\n",
       "count                     76518.000000  76518.000000            76518.000000   \n",
       "unique                             NaN           NaN                     NaN   \n",
       "top                                NaN           NaN                     NaN   \n",
       "freq                               NaN           NaN                     NaN   \n",
       "mean                        132.378766      1.226600               19.837633   \n",
       "std                          10.995328      3.392183               15.399456   \n",
       "min                          95.000000      1.000000                1.000000   \n",
       "25%                         125.000000      1.000000                1.000000   \n",
       "50%                         133.100000      1.000000               19.000000   \n",
       "75%                         140.000000      1.000000               37.000000   \n",
       "max                         190.000000    109.000000               44.000000   \n",
       "\n",
       "        ...  Curricular units 2nd sem (credited)  \\\n",
       "count   ...                         76518.000000   \n",
       "unique  ...                                  NaN   \n",
       "top     ...                                  NaN   \n",
       "freq    ...                                  NaN   \n",
       "mean    ...                             0.137053   \n",
       "std     ...                             0.933830   \n",
       "min     ...                             0.000000   \n",
       "25%     ...                             0.000000   \n",
       "50%     ...                             0.000000   \n",
       "75%     ...                             0.000000   \n",
       "max     ...                            19.000000   \n",
       "\n",
       "        Curricular units 2nd sem (enrolled)  \\\n",
       "count                          76518.000000   \n",
       "unique                                  NaN   \n",
       "top                                     NaN   \n",
       "freq                                    NaN   \n",
       "mean                               5.933414   \n",
       "std                                1.627182   \n",
       "min                                0.000000   \n",
       "25%                                5.000000   \n",
       "50%                                6.000000   \n",
       "75%                                6.000000   \n",
       "max                               23.000000   \n",
       "\n",
       "        Curricular units 2nd sem (evaluations)  \\\n",
       "count                             76518.000000   \n",
       "unique                                     NaN   \n",
       "top                                        NaN   \n",
       "freq                                       NaN   \n",
       "mean                                  7.234468   \n",
       "std                                   3.503040   \n",
       "min                                   0.000000   \n",
       "25%                                   6.000000   \n",
       "50%                                   7.000000   \n",
       "75%                                   9.000000   \n",
       "max                                  33.000000   \n",
       "\n",
       "        Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "count                          76518.000000                      76518.000000   \n",
       "unique                                  NaN                               NaN   \n",
       "top                                     NaN                               NaN   \n",
       "freq                                    NaN                               NaN   \n",
       "mean                               4.007201                          9.626085   \n",
       "std                                2.772956                          5.546035   \n",
       "min                                0.000000                          0.000000   \n",
       "25%                                1.000000                         10.000000   \n",
       "50%                                5.000000                         12.142857   \n",
       "75%                                6.000000                         13.244048   \n",
       "max                               20.000000                         18.000000   \n",
       "\n",
       "        Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "count                                     76518.000000       76518.000000   \n",
       "unique                                             NaN                NaN   \n",
       "top                                                NaN                NaN   \n",
       "freq                                               NaN                NaN   \n",
       "mean                                          0.062443          11.520340   \n",
       "std                                           0.462107           2.653375   \n",
       "min                                           0.000000           7.600000   \n",
       "25%                                           0.000000           9.400000   \n",
       "50%                                           0.000000          11.100000   \n",
       "75%                                           0.000000          12.700000   \n",
       "max                                          12.000000          16.200000   \n",
       "\n",
       "        Inflation rate           GDP    Target  \n",
       "count     76518.000000  76518.000000     76518  \n",
       "unique             NaN           NaN         3  \n",
       "top                NaN           NaN  Graduate  \n",
       "freq               NaN           NaN     36282  \n",
       "mean          1.228218     -0.080921       NaN  \n",
       "std           1.398816      2.251382       NaN  \n",
       "min          -0.800000     -4.060000       NaN  \n",
       "25%           0.300000     -1.700000       NaN  \n",
       "50%           1.400000      0.320000       NaN  \n",
       "75%           2.600000      1.790000       NaN  \n",
       "max           3.700000      3.510000       NaN  \n",
       "\n",
       "[11 rows x 38 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>12.820000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Marital status  Application mode  Application order  Course  \\\n",
       "0   0               1                 1                  1    9238   \n",
       "1   1               1                17                  1    9238   \n",
       "2   2               1                17                  2    9254   \n",
       "3   3               1                 1                  3    9500   \n",
       "4   4               1                 1                  2    9500   \n",
       "\n",
       "   Daytime/evening attendance  Previous qualification  \\\n",
       "0                           1                       1   \n",
       "1                           1                       1   \n",
       "2                           1                       1   \n",
       "3                           1                       1   \n",
       "4                           1                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  ...  \\\n",
       "0                           126.0            1                       1  ...   \n",
       "1                           125.0            1                      19  ...   \n",
       "2                           137.0            1                       3  ...   \n",
       "3                           131.0            1                      19  ...   \n",
       "4                           132.0            1                      19  ...   \n",
       "\n",
       "   Curricular units 2nd sem (credited)  Curricular units 2nd sem (enrolled)  \\\n",
       "0                                    0                                    6   \n",
       "1                                    0                                    6   \n",
       "2                                    0                                    6   \n",
       "3                                    0                                    8   \n",
       "4                                    0                                    7   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                                       7   \n",
       "1                                       9   \n",
       "2                                       0   \n",
       "3                                      11   \n",
       "4                                      12   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                    6                         12.428571   \n",
       "1                                    0                          0.000000   \n",
       "2                                    0                          0.000000   \n",
       "3                                    7                         12.820000   \n",
       "4                                    6                         12.933333   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0               11.1   \n",
       "1                                               0               11.1   \n",
       "2                                               0               16.2   \n",
       "3                                               0               11.1   \n",
       "4                                               0                7.6   \n",
       "\n",
       "   Inflation rate   GDP    Target  \n",
       "0             0.6  2.02  Graduate  \n",
       "1             0.6  2.02   Dropout  \n",
       "2             0.3 -0.92   Dropout  \n",
       "3             0.6  2.02  Enrolled  \n",
       "4             2.6  0.32  Graduate  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                  int64\n",
       "Marital status                                      int64\n",
       "Application mode                                    int64\n",
       "Application order                                   int64\n",
       "Course                                              int64\n",
       "Daytime/evening attendance                          int64\n",
       "Previous qualification                              int64\n",
       "Previous qualification (grade)                    float64\n",
       "Nacionality                                         int64\n",
       "Mother's qualification                              int64\n",
       "Father's qualification                              int64\n",
       "Mother's occupation                                 int64\n",
       "Father's occupation                                 int64\n",
       "Admission grade                                   float64\n",
       "Displaced                                           int64\n",
       "Educational special needs                           int64\n",
       "Debtor                                              int64\n",
       "Tuition fees up to date                             int64\n",
       "Gender                                              int64\n",
       "Scholarship holder                                  int64\n",
       "Age at enrollment                                   int64\n",
       "International                                       int64\n",
       "Curricular units 1st sem (credited)                 int64\n",
       "Curricular units 1st sem (enrolled)                 int64\n",
       "Curricular units 1st sem (evaluations)              int64\n",
       "Curricular units 1st sem (approved)                 int64\n",
       "Curricular units 1st sem (grade)                  float64\n",
       "Curricular units 1st sem (without evaluations)      int64\n",
       "Curricular units 2nd sem (credited)                 int64\n",
       "Curricular units 2nd sem (enrolled)                 int64\n",
       "Curricular units 2nd sem (evaluations)              int64\n",
       "Curricular units 2nd sem (approved)                 int64\n",
       "Curricular units 2nd sem (grade)                  float64\n",
       "Curricular units 2nd sem (without evaluations)      int64\n",
       "Unemployment rate                                 float64\n",
       "Inflation rate                                    float64\n",
       "GDP                                               float64\n",
       "Target                                             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "76513    False\n",
       "76514    False\n",
       "76515    False\n",
       "76516    False\n",
       "76517    False\n",
       "Length: 76518, dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76518, 37), (76518,), (76518, 38))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = train_data.drop(columns=['Target']), train_data['Target']\n",
    "X.shape, Y.shape, train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_Scaled = scaler.fit_transform(X) # normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((61214, 37), (61214,), (15304, 37), (15304,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, random_state = 111, test_size = 0.20)\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy is 70.09047692726553%\n"
     ]
    }
   ],
   "source": [
    "bagger = BaggingClassifier(estimator=DecisionTreeClassifier(), max_samples=1.0, n_estimators=9, random_state=1111)\n",
    "score = cross_val_score(bagger, X_Scaled, Y, cv=4)\n",
    "print(f'Average validation accuracy is {np.mean(score)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy is 81.44485433957801%\n"
     ]
    }
   ],
   "source": [
    "randomF = RandomForestClassifier()\n",
    "score = cross_val_score(randomF, X, Y, cv=4)\n",
    "print(f'Average validation accuracy is {np.mean(score)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy is 81.68009966557975%\n"
     ]
    }
   ],
   "source": [
    "randomF = RandomForestClassifier()\n",
    "score = cross_val_score(randomF, X_Scaled, Y, cv=4)\n",
    "print(f'Average validation accuracy is {np.mean(score)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8274960794563513"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomF100 = RandomForestClassifier(n_estimators=100, max_features=\"sqrt\")\n",
    "randomF100.fit(X_train,Y_train)\n",
    "randomF100.score(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8287375849451124"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomF1000 = RandomForestClassifier(n_estimators=1000, max_features=\"sqrt\")\n",
    "randomF1000.fit(X_train,Y_train)\n",
    "randomF1000.score(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submitModel(model, X_test):\n",
    "    Y_tilda = model.predict(X_test)\n",
    "    submission = pd.DataFrame(\n",
    "        {'id': X_test[\"id\"], 'Target': Y_tilda},\n",
    "        columns = ['id', 'Target'])\n",
    "    submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitModel(randomF1000, test_data) #0.82982\n",
    "submitModel(randomF100, test_data) #0.82523"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fidan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "X_train = train_data.iloc[:, :-1].values  \n",
    "y_train = train_data.iloc[:, -1].values    \n",
    "\n",
    "# normalize\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1],)), \n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(100, activation='relu'), \n",
    "    layers.Dense(3, activation='softmax')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1913/1913 [==============================] - 6s 3ms/step - loss: 0.4966 - accuracy: 0.8056 - val_loss: 0.4725 - val_accuracy: 0.8150\n",
      "Epoch 2/2\n",
      "1913/1913 [==============================] - 5s 3ms/step - loss: 0.4640 - accuracy: 0.8215 - val_loss: 0.4691 - val_accuracy: 0.8177\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = np.array(X_train_scaled, dtype=np.float32)\n",
    "history = model.fit(X_train_scaled, y_train_encoded, epochs=2, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  44/1595 [..............................] - ETA: 1s  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/helios/home/juangonzalo/ML_project_UT/venv/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1595/1595 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(test_data)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predicted_indices = predictions.argmax(axis=1)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submitModelPredictedLabels(predicted_labels, X_test):\n",
    "    submission = pd.DataFrame(\n",
    "        {'id': X_test[\"id\"], 'Target': predicted_labels},\n",
    "        columns = ['id', 'Target'])\n",
    "    submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitModelPredictedLabels(predicted_labels, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/helios/home/juangonzalo/ML_project_UT/venv/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "assabler = pd.DataFrame()\n",
    "X_test_scaled = scaler.transform(test_data)\n",
    "assabler[\"model1\"] = naiara_model.predict(X_test_scaled)\n",
    "assabler[\"model2\"] = randomF1000.predict(test_data)\n",
    "assabler[\"model3\"] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Dropout\n",
      "1    Graduate\n",
      "2    Graduate\n",
      "3    Graduate\n",
      "4    Enrolled\n",
      "Name: ensemble, dtype: object\n"
     ]
    }
   ],
   "source": [
    "assabler['ensemble'] = assabler[[\"model1\", \"model2\", \"model3\"]].mode(axis=1)[0]\n",
    "print(assabler['ensemble'].head())\n",
    "submitModelPredictedLabels(assabler['ensemble'], test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
