{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/naiaraAM/ML_project_UT/blob/main/Project_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzV8D8bXC4lw"
   },
   "source": [
    "# Set up enviroment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrh42OERGJnQ"
   },
   "source": [
    "# Download data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "MobMyN7kGOZS",
    "outputId": "e36928ec-8f8b-4f07-c8a1-6795bd4b8c92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open playground-series-s4e6.zip, playground-series-s4e6.zip.zip or playground-series-s4e6.zip.ZIP.\n",
      "rm: playground-series-s4e6.zip: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!unzip -q playground-series-s4e6.zip -d data\n",
    "!rm playground-series-s4e6.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAKgcDH_F13K",
    "outputId": "ef4a9512-2644-4c37-85b7-5aadaf4304e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data has 76518 rows and 38 columns\n",
      "The test data has 51012 rows and 37 columns\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(f\"The train data has {train_data.shape[0]} rows and {train_data.shape[1]} columns\")\n",
    "print(f\"The test data has {test_data.shape[0]} rows and {test_data.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Do your code in the cell bellow your name, so we don't have merge issues. We can merge on friday's meeting</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naiara\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: Marital status\n",
      "Processing feature: Application mode\n",
      "Processing feature: Application order\n",
      "Processing feature: Course\n",
      "Processing feature: Daytime/evening attendance\n",
      "Error processing feature Daytime/evening attendance: [Errno 2] No such file or directory: '/Users/fidansuleymanova/ML_project_UT/plots/Daytime/evening attendance_percentage_plot.png'\n",
      "Processing feature: Previous qualification\n",
      "Processing feature: Nacionality\n",
      "Processing feature: Mother's qualification\n",
      "Processing feature: Father's qualification\n",
      "Processing feature: Mother's occupation\n",
      "Processing feature: Father's occupation\n",
      "Processing feature: Displaced\n",
      "Processing feature: Educational special needs\n",
      "Processing feature: Debtor\n",
      "Processing feature: Tuition fees up to date\n",
      "Processing feature: Gender\n",
      "Processing feature: Scholarship holder\n",
      "Processing feature: Age at enrollment\n",
      "Processing feature: International\n",
      "Processing feature: Curricular units 1st sem (credited)\n",
      "Processing feature: Curricular units 1st sem (enrolled)\n",
      "Processing feature: Curricular units 1st sem (evaluations)\n",
      "Processing feature: Curricular units 1st sem (approved)\n",
      "Processing feature: Curricular units 1st sem (without evaluations)\n",
      "Processing feature: Curricular units 2nd sem (credited)\n",
      "Processing feature: Curricular units 2nd sem (enrolled)\n",
      "Processing feature: Curricular units 2nd sem (evaluations)\n",
      "Processing feature: Curricular units 2nd sem (approved)\n",
      "Processing feature: Curricular units 2nd sem (without evaluations)\n",
      "Processing feature: Unemployment rate\n",
      "Processing feature: Inflation rate\n",
      "Processing feature: GDP\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import matplotlib\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "\n",
    "features = train_data.columns[:-1]\n",
    "\n",
    "max_unique_values = 100  # Different possible values for feature\n",
    "features = [f for f in features if train_data[f].nunique() <= max_unique_values]\n",
    "\n",
    "output_dir = 'plots'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "batch_size = 5\n",
    "for i in range(0, len(features), batch_size):\n",
    "    batch_features = features[i:i + batch_size]\n",
    "    \n",
    "    for feature in batch_features:\n",
    "        try:\n",
    "            print(f\"Processing feature: {feature}\")\n",
    "            percentage = train_data.groupby(feature)['Target'].value_counts(normalize=True).unstack() * 100\n",
    "            \n",
    "            # Plot and save\n",
    "            ax = percentage.plot(kind='bar', stacked=True, colormap='viridis', legend=False)\n",
    "            plt.xlabel(feature)\n",
    "            plt.ylabel('Percentage')\n",
    "            plt.title(f'Percentage of Each Target Value per {feature} Value')\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            plt.legend(handles, labels, title='Target')\n",
    "\n",
    "            # Save plot\n",
    "            plot_filename = os.path.join(output_dir, f'{feature}_percentage_plot.png')\n",
    "            plt.savefig(plot_filename)\n",
    "            plt.close()\n",
    "            #print(f\"Saved plot for feature: {feature}\")\n",
    "            \n",
    "            time.sleep(0.5)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing feature {feature}: {e}\")\n",
    "\n",
    "        gc.collect()  # Clear memory\n",
    "    \n",
    "    #print(f\"Batch {i // batch_size + 1} completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submitModel(model, X_test):\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    Y_tilda = model.predict(X_test_scaled)\n",
    "    submission = pd.DataFrame(\n",
    "        {'id': X_test[\"id\"], 'Target': Y_tilda},\n",
    "        columns = ['id', 'Target'])\n",
    "    submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m submitModel(\u001b[43mbest_model\u001b[49m, test_data) \u001b[38;5;66;03m# 0.82420\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "submitModel(best_model, test_data) # 0.82420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(models, filename: str):\n",
    "    for index, model in enumerate(models):\n",
    "        filename_aux = filename + f'_{index}.pkl'\n",
    "        with open(filename_aux, 'wb') as file:  \n",
    "            pickle.dump(model, file)\n",
    "            print(f\"Saved with the name {filename_aux}\")\n",
    "\n",
    "# TODO: I need to fix this\n",
    "def load_model(filename: str):\n",
    "    with open(filename, 'rb') as file:  \n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-equal performance on public-private score, public is always better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "X = train_data.iloc[:, :-1]\n",
    "y = train_data.iloc[:, -1]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(y.value_counts())\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "gbt_model = GradientBoostingClassifier(n_estimators=350, learning_rate=0.03, max_depth=5)\n",
    "\n",
    "gbt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val = gbt_model.predict(X_val)\n",
    "\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "print(f\"Validation Accuracy: {accuracy_val:.4f}\")\n",
    "\n",
    "print(classification_report(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"XXXXX_gbt_model.pkl\"\n",
    "save_model(filename)\n",
    "#model = load_model(filename)\n",
    "\n",
    "y_test = model.predict(X_test_pca)\n",
    "y_test = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'id': test_data[\"id\"], 'Target': y_test},\n",
    "    columns=['id', 'Target']\n",
    ")\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved as 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_depth = {\n",
    "    'n_estimators': [200, 200, 200, 200, 200, 200, 200, 200, 200],\n",
    "    'learning_rate': [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05],\n",
    "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'accuracy': [0.8149, 0.8225, 0.8268, 0.8265, 0.8218, 0.8317, 0.8295, 0.8308, 0.8300],\n",
    "    'private score': [0.82227, 0.82737, 0.83055, 0.83124, 0.83094, 0.83119, 0.82378, 0.82337, 0.82276],\n",
    "    'public score': [0.81915, 0.82513, 0.82915, 0.83022, 0.83199, 0.83120, 0.83150, 0.82111, 0.81866]\n",
    "}\n",
    "\n",
    "df_depth = pd.DataFrame(data_depth)\n",
    "\n",
    "df_styled = df_depth.style.background_gradient(subset=[\"accuracy\", \"public score\", \"private score\"], cmap=\"RdYlGn\", vmin=0.8148, vmax=0.84)\n",
    "\n",
    "df_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_learning_rate = {\n",
    "    'n_estimators': [200, 200, 200, 200, 200, 200],\n",
    "    'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06],\n",
    "    'max_depth': [6, 6, 6, 6, 6, 6],\n",
    "    'accuracy': [0.8228, 0.8291, 0.8304, 0.8304, 0.8306, 0.8298],\n",
    "    'private score': [0.82599, 0.82969, 0.83126, 0.83094, 0.82967, 0.82435],\n",
    "    'public score': [0.82464, 0.82826, 0.82856, 0.83071, 0.83179, 0.82415]\n",
    "}\n",
    "\n",
    "df_learning_rate = pd.DataFrame(data_learning_rate)\n",
    "\n",
    "df_styled = df_learning_rate.style.background_gradient(subset=[\"accuracy\", \"public score\", \"private score\"], cmap=\"RdYlGn\", vmin=0.821, vmax=0.84)\n",
    "\n",
    "df_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_estimators = {\n",
    "    'n_estimators': [50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300],\n",
    "    'learning_rate': [0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03],\n",
    "    'max_depth': [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6],\n",
    "    'accuracy': [0.8200, 0.8248, 0.8276, 0.8284, 0.8292, 0.8296, 0.8304, 0.8306, 0.8314, 0.8311, 0.8314],\n",
    "    'private score': [0.82349, 0.82683, 0.82854, 0.82967, 0.83092, 0.83109, 0.83146, 0.83002, 0.83033, 0.83075, 0.83053],\n",
    "    'public score': [0.82268, 0.82503, 0.82738, 0.82866, 0.82866, 0.82875, 0.82787, 0.83022, 0.83091, 0.83052, 0.83120]\n",
    "}\n",
    "\n",
    "df_estimators = pd.DataFrame(data_estimators)\n",
    "\n",
    "df_styled = df_estimators.style.background_gradient(subset=[\"accuracy\", \"public score\", \"private score\"], cmap=\"RdYlGn\", vmin=0.8148, vmax=0.84)\n",
    "\n",
    "df_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_estimators = {\n",
    "    'n_estimators': [300, 350],\n",
    "    'learning_rate': [0.03, 0.03],\n",
    "    'max_depth': [5, 5],\n",
    "    'private score': [0.83080, 0.83082],\n",
    "    'public score': [0.83189, 0.83238]\n",
    "}\n",
    "\n",
    "df_estimators = pd.DataFrame(data_estimators)\n",
    "\n",
    "df_styled = df_estimators.style.background_gradient(subset=[\"public score\", \"private score\"], cmap=\"RdYlGn\", vmin=0.8148, vmax=0.84)\n",
    "\n",
    "df_styled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has similar performance on private-public, but the other approach is better.\n",
    "\n",
    "What this approach does. Separated the tags into three groups:\n",
    "* 0 and 1 (after label encoder)\n",
    "* 0 and 2 (after label encoder)\n",
    "* 1 and 2 (after label encoder)\n",
    "  \n",
    "Train the three models separately. Then combines\n",
    "* if prediction from `model_01` and `model_02`, then prediction is `0`\n",
    "* if prediction from `model_01` and `model_12`, then prediction is `1`\n",
    "* if prediction from `model_02` and `model_12`, then prediction is `2`\n",
    "* else majority voting\n",
    "\n",
    "I realised that the models struggle to predict for class `1`. If I change the `GradientBoostingClassifier` to `HistGradientBoostingClassifier` it performs a little b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "X = train_data.iloc[:, :-1]\n",
    "y = train_data.iloc[:, -1]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "X_train_01 = X_train[(y_train == 0) | (y_train == 1)]\n",
    "y_train_01 = y_train[(y_train == 0) | (y_train == 1)]\n",
    "X_val_01 = X_val[(y_val == 0) | (y_val == 1)]\n",
    "y_val_01 = y_val[(y_val == 0) | (y_val == 1)]\n",
    "\n",
    "X_train_02 = X_train[(y_train == 0) | (y_train == 2)]\n",
    "y_train_02 = y_train[(y_train == 0) | (y_train == 2)]\n",
    "X_val_02 = X_val[(y_val == 0) | (y_val == 2)]\n",
    "y_val_02 = y_val[(y_val == 0) | (y_val == 2)]\n",
    "\n",
    "X_train_12 = X_train[(y_train == 1) | (y_train == 2)]\n",
    "y_train_12 = y_train[(y_train == 1) | (y_train == 2)]\n",
    "X_val_12 = X_val[(y_val == 1) | (y_val == 2)]\n",
    "y_val_12 = y_val[(y_val == 1) | (y_val == 2)]\n",
    "\n",
    "model_01 = GradientBoostingClassifier(n_estimators=350, learning_rate=0.03, max_depth=5)\n",
    "model_01.fit(X_train_01, y_train_01)\n",
    "y_pred_val_01 = model_01.predict(X_val_01)\n",
    "accuracy_val = accuracy_score(y_val_01, y_pred_val_01)\n",
    "print(f\"Validation Accuracy for model 01: {accuracy_val:.4f}\")\n",
    "print(classification_report(y_val_01, y_pred_val_01))\n",
    "\n",
    "model_02 = GradientBoostingClassifier(n_estimators=350, learning_rate=0.03, max_depth=5)\n",
    "model_02.fit(X_train_02, y_train_02)\n",
    "y_pred_val_02 = model_02.predict(X_val_02)\n",
    "accuracy_val = accuracy_score(y_val_02, y_pred_val_02)\n",
    "print(f\"Validation Accuracy for model 02: {accuracy_val:.4f}\")\n",
    "print(classification_report(y_val_02, y_pred_val_02))\n",
    "\n",
    "model_12 = GradientBoostingClassifier(n_estimators=350, learning_rate=0.03, max_depth=5)\n",
    "model_12.fit(X_train_12, y_train_12)\n",
    "y_pred_val_12 = model_12.predict(X_val_12)\n",
    "accuracy_val = accuracy_score(y_val_12, y_pred_val_12)\n",
    "print(f\"Validation Accuracy for model 12: {accuracy_val:.4f}\")\n",
    "print(classification_report(y_val_12, y_pred_val_12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "def predict(X_data):\n",
    "    final_predictions = []\n",
    "    \n",
    "    for X_pred_data in X_data:\n",
    "        # Predictions for every model\n",
    "        predict_01 = model_01.predict([X_pred_data])[0]\n",
    "        predict_02 = model_02.predict([X_pred_data])[0]\n",
    "        predict_12 = model_12.predict([X_pred_data])[0]\n",
    "        \n",
    "        if predict_01 == predict_02:  # High chance of being class 0\n",
    "            prediction = 0\n",
    "        elif predict_01 == predict_12:  # High change of being class 1\n",
    "            prediction = 1\n",
    "        elif predict_02 == predict_12:  # High chance of being class 2\n",
    "            prediction = 2\n",
    "        else:  # mayority voto\n",
    "            votes = [predict_01, predict_02, predict_12]\n",
    "            prediction = max(set(votes), key=votes.count)\n",
    "        final_predictions.append(prediction)\n",
    "    return np.array(final_predictions)\n",
    "    \n",
    "final_predictions = predict(X_val)\n",
    "\n",
    "accuracy_val_ensemble = accuracy_score(y_val, final_predictions)\n",
    "print(f\"Validation Accuracy for Ensemble Model: {accuracy_val_ensemble:.4f}\")\n",
    "\n",
    "print(classification_report(y_val, final_predictions, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_01, model_02, model_12]\n",
    "filename = \"XXXXX_gbc_ensemble_model\"\n",
    "save_model(models, filename)\n",
    "#model = load_model(filename)\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(test_data)\n",
    "final_predictions = predict(X_scaled)\n",
    "y_test = label_encoder.inverse_transform(final_predictions)\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'id': test_data[\"id\"], 'Target': y_test},\n",
    "    columns=['id', 'Target']\n",
    ")\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved as 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = train_data.drop(columns=['Target']), train_data['Target']\n",
    "X.shape, Y.shape, train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_Scaled = scaler.fit_transform(X) # normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, random_state = 111, test_size = 0.20)\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagger = BaggingClassifier(estimator=DecisionTreeClassifier(), max_samples=1.0, n_estimators=9, random_state=1111)\n",
    "score = cross_val_score(bagger, X_Scaled, Y, cv=4)\n",
    "print(f'Average validation accuracy is {np.mean(score)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomF = RandomForestClassifier()\n",
    "score = cross_val_score(randomF, X, Y, cv=4)\n",
    "print(f'Average validation accuracy is {np.mean(score)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomF = RandomForestClassifier()\n",
    "score = cross_val_score(randomF, X_Scaled, Y, cv=4)\n",
    "print(f'Average validation accuracy is {np.mean(score)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomF100 = RandomForestClassifier(n_estimators=100, max_features=\"sqrt\")\n",
    "randomF100.fit(X_train,Y_train)\n",
    "randomF100.score(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomF1000 = RandomForestClassifier(n_estimators=1000, max_features=\"sqrt\")\n",
    "randomF1000.fit(X_train,Y_train)\n",
    "randomF1000.score(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submitModel(model, X_test):\n",
    "    Y_tilda = model.predict(X_test)\n",
    "    submission = pd.DataFrame(\n",
    "        {'id': X_test[\"id\"], 'Target': Y_tilda},\n",
    "        columns = ['id', 'Target'])\n",
    "    submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitModel(randomF1000, test_data) #0.82982\n",
    "submitModel(randomF100, test_data) #0.82523"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fidan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "X_train = train_data.iloc[:, :-1].values  \n",
    "y_train = train_data.iloc[:, -1].values    \n",
    "\n",
    "# normalize\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train) \n",
    "y_train_onehot = to_categorical(y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1],)),  \n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dense(len(label_encoder.classes_), activation='softmax') \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352us/step - accuracy: 0.8415 - loss: 0.4144 - val_accuracy: 0.8116 - val_loss: 0.4844\n",
      "Epoch 2/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332us/step - accuracy: 0.8400 - loss: 0.4148 - val_accuracy: 0.8100 - val_loss: 0.4916\n",
      "Epoch 3/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315us/step - accuracy: 0.8434 - loss: 0.4071 - val_accuracy: 0.8133 - val_loss: 0.4888\n",
      "Epoch 4/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323us/step - accuracy: 0.8448 - loss: 0.4035 - val_accuracy: 0.8103 - val_loss: 0.4954\n",
      "Epoch 5/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step - accuracy: 0.8420 - loss: 0.4109 - val_accuracy: 0.8091 - val_loss: 0.4943\n",
      "Epoch 6/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341us/step - accuracy: 0.8430 - loss: 0.4063 - val_accuracy: 0.8131 - val_loss: 0.4910\n",
      "Epoch 7/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322us/step - accuracy: 0.8439 - loss: 0.4043 - val_accuracy: 0.8135 - val_loss: 0.4937\n",
      "Epoch 8/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315us/step - accuracy: 0.8438 - loss: 0.4044 - val_accuracy: 0.8076 - val_loss: 0.5011\n",
      "Epoch 9/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312us/step - accuracy: 0.8439 - loss: 0.4026 - val_accuracy: 0.8093 - val_loss: 0.5013\n",
      "Epoch 10/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331us/step - accuracy: 0.8460 - loss: 0.4004 - val_accuracy: 0.8086 - val_loss: 0.5008\n",
      "Epoch 11/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309us/step - accuracy: 0.8415 - loss: 0.4011 - val_accuracy: 0.8089 - val_loss: 0.5049\n",
      "Epoch 12/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312us/step - accuracy: 0.8447 - loss: 0.3986 - val_accuracy: 0.8072 - val_loss: 0.5047\n",
      "Epoch 13/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317us/step - accuracy: 0.8477 - loss: 0.3970 - val_accuracy: 0.8067 - val_loss: 0.5022\n",
      "Epoch 14/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319us/step - accuracy: 0.8453 - loss: 0.3962 - val_accuracy: 0.8065 - val_loss: 0.5069\n",
      "Epoch 15/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313us/step - accuracy: 0.8496 - loss: 0.3940 - val_accuracy: 0.8081 - val_loss: 0.5176\n",
      "Epoch 16/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323us/step - accuracy: 0.8515 - loss: 0.3871 - val_accuracy: 0.8083 - val_loss: 0.5132\n",
      "Epoch 17/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339us/step - accuracy: 0.8507 - loss: 0.3887 - val_accuracy: 0.8036 - val_loss: 0.5166\n",
      "Epoch 18/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314us/step - accuracy: 0.8478 - loss: 0.3904 - val_accuracy: 0.8046 - val_loss: 0.5151\n",
      "Epoch 19/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336us/step - accuracy: 0.8516 - loss: 0.3870 - val_accuracy: 0.8085 - val_loss: 0.5185\n",
      "Epoch 20/20\n",
      "\u001b[1m1913/1913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320us/step - accuracy: 0.8482 - loss: 0.3898 - val_accuracy: 0.8083 - val_loss: 0.5236\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = np.array(X_train_scaled, dtype=np.float32)\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_onehot, \n",
    "    epochs=20, batch_size=32, validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1595/1595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203us/step\n"
     ]
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(test_data.values)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predicted_indices = predictions.argmax(axis=1)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submitModelPredictedLabels(predicted_labels, X_test):\n",
    "    submission = pd.DataFrame(\n",
    "        {'id': X_test[\"id\"], 'Target': predicted_labels},\n",
    "        columns = ['id', 'Target'])\n",
    "    submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitModelPredictedLabels(predicted_labels, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fidansuleymanova/ML_project_UT/venv/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'naiara_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m assabler \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      2\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(test_data)\n\u001b[0;32m----> 3\u001b[0m assabler[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnaiara_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n\u001b[1;32m      4\u001b[0m assabler[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m randomF1000\u001b[38;5;241m.\u001b[39mpredict(test_data)\n\u001b[1;32m      5\u001b[0m assabler[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel3\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m predicted_labels\n",
      "\u001b[0;31mNameError\u001b[0m: name 'naiara_model' is not defined"
     ]
    }
   ],
   "source": [
    "assabler = pd.DataFrame()\n",
    "X_test_scaled = scaler.transform(test_data)\n",
    "assabler[\"model1\"] = naiara_model.predict(X_test_scaled)\n",
    "assabler[\"model2\"] = randomF1000.predict(test_data)\n",
    "assabler[\"model3\"] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assabler['ensemble'] = assabler[[\"model1\", \"model2\", \"model3\"]].mode(axis=1)[0]\n",
    "print(assabler['ensemble'].head())\n",
    "submitModelPredictedLabels(assabler['ensemble'], test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
